(self.webpackChunk_N_E=self.webpackChunk_N_E||[]).push([[931],{208:function(e,a,s){Promise.resolve().then(s.bind(s,8836))},8836:function(e,a,s){"use strict";s.r(a),s.d(a,{default:function(){return c}});var t=s(3827);s(4090);var r=s(2175),i=s(2707),n=s(3251),l=s(32);function c(){return(0,t.jsxs)("main",{className:"min-h-screen",children:[(0,t.jsx)("section",{className:"min-h-screen flex items-center justify-center bg-gradient-to-b from-white to-gray-100 dark:from-gray-900 dark:to-gray-800",children:(0,t.jsxs)("div",{className:"container mx-auto px-4 py-16 text-center",children:[(0,t.jsx)(r.E.h1,{initial:{opacity:0,y:20},animate:{opacity:1,y:0},transition:{duration:.5},className:"text-5xl font-bold mb-4",children:"Hansheng Zhu"}),(0,t.jsx)(r.E.p,{initial:{opacity:0,y:20},animate:{opacity:1,y:0},transition:{duration:.5,delay:.2},className:"text-xl text-gray-600 dark:text-gray-300 mb-8",children:"AI Engineer & Researcher at UPenn"}),(0,t.jsxs)(r.E.div,{initial:{opacity:0,y:20},animate:{opacity:1,y:0},transition:{duration:.5,delay:.4},className:"flex justify-center space-x-6",children:[(0,t.jsxs)("a",{href:"mailto:hanszhu@seas.upenn.edu",className:"flex items-center space-x-2 hover:text-blue-600",children:[(0,t.jsx)(i.Z,{className:"h-5 w-5"}),(0,t.jsx)("span",{children:"hanszhu@seas.upenn.edu"})]}),(0,t.jsxs)("a",{href:"tel:+14458005280",className:"flex items-center space-x-2 hover:text-blue-600",children:[(0,t.jsx)(n.Z,{className:"h-5 w-5"}),(0,t.jsx)("span",{children:"(445) 800-5280"})]}),(0,t.jsxs)("a",{href:"https://github.com/hanshengzhu0001",target:"_blank",rel:"noopener noreferrer",className:"flex items-center space-x-2 hover:text-blue-600",children:[(0,t.jsx)(l.Z,{className:"h-5 w-5"}),(0,t.jsx)("span",{children:"GitHub"})]})]})]})}),(0,t.jsx)("section",{className:"py-20 bg-white dark:bg-gray-900",children:(0,t.jsxs)("div",{className:"container mx-auto px-4",children:[(0,t.jsx)("h2",{className:"text-3xl font-bold mb-8 text-center",children:"Education"}),(0,t.jsx)("div",{className:"max-w-3xl mx-auto",children:(0,t.jsxs)("div",{className:"bg-gray-50 dark:bg-gray-800 rounded-lg p-6 shadow-lg",children:[(0,t.jsx)("h3",{className:"text-xl font-semibold mb-2",children:"University of Pennsylvania"}),(0,t.jsx)("p",{className:"text-gray-600 dark:text-gray-300 mb-2",children:"School of Engineering and Applied Sciences"}),(0,t.jsx)("p",{className:"text-gray-600 dark:text-gray-300 mb-4",children:"Rising Junior • GPA: 3.80"}),(0,t.jsx)("p",{className:"text-gray-600 dark:text-gray-300 mb-4",children:"Candidate for Bachelor of Engineering in Artificial Intelligence"}),(0,t.jsxs)("div",{className:"mt-4",children:[(0,t.jsx)("h4",{className:"font-semibold mb-2",children:"Relevant Coursework:"}),(0,t.jsx)("p",{className:"text-gray-600 dark:text-gray-300",children:"Machine Learning, Signal Processing, Data Structures and Algorithms, Stochastic Processes, Artificial Intelligence, Machine Perception, Neural Networks, Brain Computer Interface, OOP"})]})]})})]})}),(0,t.jsx)("section",{className:"py-20 bg-gray-50 dark:bg-gray-800",children:(0,t.jsxs)("div",{className:"container mx-auto px-4",children:[(0,t.jsx)("h2",{className:"text-3xl font-bold mb-8 text-center",children:"Work Experience"}),(0,t.jsxs)("div",{className:"max-w-3xl mx-auto space-y-6",children:[(0,t.jsxs)("div",{className:"bg-white dark:bg-gray-900 rounded-lg p-6 shadow-lg",children:[(0,t.jsx)("h3",{className:"text-xl font-semibold mb-2",children:"Software Development Intern"}),(0,t.jsx)("p",{className:"text-gray-600 dark:text-gray-300 mb-2",children:"Astoria AI • Jan 2025 - Present"}),(0,t.jsxs)("ul",{className:"list-disc list-inside text-gray-600 dark:text-gray-300",children:[(0,t.jsx)("li",{children:"Designed and optimized LLM-as-a-Judge evaluation pipeline for conversational AI"}),(0,t.jsx)("li",{children:"Built scalable frontend modules for talent management platform"})]})]}),(0,t.jsxs)("div",{className:"bg-white dark:bg-gray-900 rounded-lg p-6 shadow-lg",children:[(0,t.jsx)("h3",{className:"text-xl font-semibold mb-2",children:"Deep Learning Research Intern"}),(0,t.jsx)("p",{className:"text-gray-600 dark:text-gray-300 mb-2",children:"Thomas Jefferson University Hospital • Oct 2024 - Present"}),(0,t.jsxs)("ul",{className:"list-disc list-inside text-gray-600 dark:text-gray-300",children:[(0,t.jsx)("li",{children:"Performed image segmentation on digital subtraction angiograms through neural networks"}),(0,t.jsx)("li",{children:"Implemented vision transformer to predict risk of capillary abnormalities"})]})]})]})]})}),(0,t.jsx)("section",{className:"py-20 bg-white dark:bg-gray-900",children:(0,t.jsxs)("div",{className:"container mx-auto px-4",children:[(0,t.jsx)("h2",{className:"text-3xl font-bold mb-8 text-center",children:"Technical Projects"}),(0,t.jsxs)("div",{className:"grid grid-cols-1 md:grid-cols-2 gap-6 max-w-4xl mx-auto",children:[(0,t.jsxs)("div",{className:"bg-gray-50 dark:bg-gray-800 rounded-lg p-6 shadow-lg",children:[(0,t.jsx)("h3",{className:"text-xl font-semibold mb-2",children:"Alziaid iOS App"}),(0,t.jsx)("p",{className:"text-gray-600 dark:text-gray-300 mb-4",children:"Swift, React"}),(0,t.jsx)("p",{className:"text-gray-600 dark:text-gray-300",children:"Led team of 4 to build a patient monitoring app with real-time health alerts; deployed for 100+ beta users."})]}),(0,t.jsxs)("div",{className:"bg-gray-50 dark:bg-gray-800 rounded-lg p-6 shadow-lg",children:[(0,t.jsx)("h3",{className:"text-xl font-semibold mb-2",children:"Plant Disease Detection"}),(0,t.jsx)("p",{className:"text-gray-600 dark:text-gray-300 mb-4",children:"PyTorch, ResNet"}),(0,t.jsx)("p",{className:"text-gray-600 dark:text-gray-300",children:"Trained CNN model for leaf image classification (95% accuracy); can be integrated into open-source agriculture toolkit."})]}),(0,t.jsxs)("div",{className:"bg-gray-50 dark:bg-gray-800 rounded-lg p-6 shadow-lg",children:[(0,t.jsx)("h3",{className:"text-xl font-semibold mb-2",children:"MedScanner"}),(0,t.jsx)("p",{className:"text-gray-600 dark:text-gray-300 mb-4",children:"React, AWS, BioBERT"}),(0,t.jsx)("p",{className:"text-gray-600 dark:text-gray-300",children:"Full-stack app for drug dosage search and assistance; optimized AWS Lambda functions to handle 500+ daily queries."})]}),(0,t.jsxs)("div",{className:"bg-gray-50 dark:bg-gray-800 rounded-lg p-6 shadow-lg",children:[(0,t.jsx)("h3",{className:"text-xl font-semibold mb-2",children:"Finger Movement Prediction"}),(0,t.jsx)("p",{className:"text-gray-600 dark:text-gray-300 mb-4",children:"Python, CuML, scikit-learn"}),(0,t.jsx)("p",{className:"text-gray-600 dark:text-gray-300",children:"Developed a multiscale high-γ/β feature extraction pipeline with GPU-accelerated Random Forests."})]})]}),(0,t.jsxs)("div",{className:"max-w-4xl mx-auto mt-10",children:[(0,t.jsxs)("div",{className:"bg-gray-50 dark:bg-gray-800 rounded-lg p-6 shadow-lg mb-6",children:[(0,t.jsx)("h3",{className:"text-xl font-semibold mb-2",children:(0,t.jsx)("a",{href:"https://github.com/hanshengzhu0001/SciChartVision",target:"_blank",rel:"noopener noreferrer",className:"text-blue-600 hover:underline",children:"SciChartVision"})}),(0,t.jsx)("p",{className:"text-gray-600 dark:text-gray-300 mb-4",children:"AI/ML, VLM, Computer Vision, REST API, SQL, Git, HF Model Inference Endpoints Management"}),(0,t.jsxs)("p",{className:"text-gray-600 dark:text-gray-300",children:["A Dense Captioning platform on Supabase that lets users select and annotate detected chart elements on scientific figures. Built a scientific chart detection model leveraging a Swin Transformer backbone with Mask R-CNN for small, dense data points and 21 other chart elements. ",(0,t.jsx)("br",{}),(0,t.jsx)("span",{className:"font-medium",children:"Deployed application enables element selection during voiceover, boosting grounding and visual understanding."})]})]}),(0,t.jsxs)("div",{className:"grid grid-cols-1 md:grid-cols-2 gap-6",children:[(0,t.jsx)("img",{src:"/demo 1.gif",alt:"SciChartVision Demo 1",className:"rounded-lg shadow-md"}),(0,t.jsx)("img",{src:"/demo 2.gif",alt:"SciChartVision Demo 2",className:"rounded-lg shadow-md"}),(0,t.jsx)("img",{src:"/demo 3.gif",alt:"SciChartVision Demo 3",className:"rounded-lg shadow-md"}),(0,t.jsx)("img",{src:"/demo 4.gif",alt:"SciChartVision Demo 4",className:"rounded-lg shadow-md"})]})]})]})}),(0,t.jsx)("section",{className:"py-20 bg-gray-50 dark:bg-gray-800",children:(0,t.jsxs)("div",{className:"container mx-auto px-4",children:[(0,t.jsx)("h2",{className:"text-3xl font-bold mb-8 text-center",children:"Current Research"}),(0,t.jsx)("div",{className:"max-w-3xl mx-auto",children:(0,t.jsx)("div",{className:"bg-white dark:bg-gray-900 rounded-lg p-6 shadow-lg",children:(0,t.jsx)("p",{className:"text-gray-600 dark:text-gray-300",children:"Working with Professor Chris Callison-Burch on building on MOLMO - a family of open state-of-the-art multimodal AI models - applying dense audio captioning and combining ViT-based image encoding with LLM-based decoding."})})})]})})]})}}},function(e){e.O(0,[105,971,69,744],function(){return e(e.s=208)}),_N_E=e.O()}]);